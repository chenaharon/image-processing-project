# Data Directory

This directory holds dataset layout, metadata, and preprocessing scripts. **Raw video files are not in the repository** (they are listed in the project [.gitignore](../.gitignore)).

---

## Dataset download and placement

Heavy files (videos) are **not** stored in the repo. To run training and evaluation you must either download the dataset (if a link is provided) or place your own videos in the correct folders.

### If a dataset link is provided

- Download the dataset from the link given in the **main [README.md](../README.md)** (section “Dataset”).
- Extract or copy the videos so that you have one folder per **class** under `data/videos/`:

  ```
  data/videos/
  ├── hand_wave_hello/
  ├── hand_wave_side/
  └── walking/
  ```

- Each folder should contain video files (e.g. `.mp4`, `.mov`). Folder names must match the class labels above.

### If you use your own videos

- Create the same structure: `data/videos/hand_wave_hello/`, `data/videos/hand_wave_side/`, `data/videos/walking/`.
- Baseline and Improved pipelines use only `hand_wave_side` and `walking`; Multiclass and Deep Learning use all three.

---

## Directory structure (recommended)

```
data/
├── videos/                    # Raw videos (NOT in git – you add these)
│   ├── hand_wave_hello/
│   │   ├── HELLO_1.mp4
│   │   └── ...
│   ├── hand_wave_side/
│   └── walking/
├── metadata/                  # Generated by pipelines (IN git)
│   ├── train_labels.csv
│   ├── val_labels.csv
│   ├── test_labels.csv
│   └── (optional) dataset_info.txt
├── unseen_videos/             # Optional: extra test videos by class
│   ├── hand_wave_hello/
│   ├── hand_wave_side/
│   └── walking/
├── prepare_dataset.py         # Used by pipelines for split
├── split_dataset.py           # Standalone split script
├── prepare_videos.py          # Resize, extract frames, organize
├── dataset_info_template.txt  # Template for dataset documentation
└── README.md                  # This file
```

---

## How the dataset is used

- When you run a pipeline (e.g. via `run_pipeline.py`), the code uses **`prepare_dataset.py`** to:
  - Check that `data/videos/` exists and has videos in the class subfolders.
  - Split videos into **train / validation / test** (e.g. 70% / 15% / 15%) with a fixed seed.
  - Write `data/metadata/train_labels.csv`, `val_labels.csv`, `test_labels.csv`.
- You do **not** need to run a separate “prepare dataset” step before `run_pipeline.py`; the pipeline does it when needed.

---

## Scripts

### `prepare_dataset.py`

Used internally by the pipelines. It verifies videos, performs the train/val/test split, and writes the metadata CSVs. You can also call it from other code that needs the same split.

### `split_dataset.py` — manual split

If you want to generate the metadata CSVs yourself (e.g. different ratios or seed):

```bash
python split_dataset.py \
    --input-dir data/videos \
    --output-dir data/metadata \
    --train-ratio 0.7 \
    --val-ratio 0.15 \
    --test-ratio 0.15 \
    --seed 42
```

- Ensures no video appears in more than one set.
- Uses stratified split by class.
- Creates `train_labels.csv`, `val_labels.csv`, `test_labels.csv` in `--output-dir`.

### `prepare_videos.py` — video utilities

```bash
# Resize
python prepare_videos.py --mode resize --input video.mp4 --output resized.mp4 --size 640x480

# Extract frames
python prepare_videos.py --mode extract-frames --input video.mp4 --output frames/ --interval 10

# Info
python prepare_videos.py --mode info --input video.mp4

# Organize by category
python prepare_videos.py --mode organize --input raw_videos/ --output organized/
```

---

## Metadata CSV format

The split scripts and pipelines produce CSVs like:

```csv
video_path,label
/path/to/data/videos/hand_wave_hello/HELLO_1.mp4,hand_wave_hello
/path/to/data/videos/hand_wave_side/vid_02.mp4,hand_wave_side
/path/to/data/videos/walking/walk_01.mp4,walking
```

- **video_path**: Absolute or relative path to the video file.
- **label**: One of `hand_wave_hello`, `hand_wave_side`, `walking`.

---

## Avoiding data leakage

- Each video should appear in **only one** of train / val / test.
- The scripts split **by video**, not by frame, so the same clip is not in multiple sets.
- Use a fixed seed (e.g. 42) for reproducibility.

---

## Loading data in code

```python
import pandas as pd

# Load metadata (after a pipeline or split_dataset.py has run)
train_df = pd.read_csv('data/metadata/train_labels.csv')
video_paths = train_df['video_path'].tolist()
labels = train_df['label'].tolist()

# Optional: map labels to ids
label_to_id = {label: idx for idx, label in enumerate(train_df['label'].unique())}
label_ids = [label_to_id[label] for label in labels]
```

---

## Dataset requirements (guidelines)

- **Per class:** at least a few videos (e.g. 10–15) for reasonable training.
- **Total:** e.g. 30–50+ videos across classes.
- **Length:** short clips (e.g. 3–10 seconds) are typical; pipelines can handle longer videos.

---

## Notes

- Keep raw videos outside the repository (they are in `.gitignore`).
- Only metadata CSVs and scripts are committed.
- Use `dataset_info_template.txt` to document your dataset and save as `metadata/dataset_info.txt` if you want.
